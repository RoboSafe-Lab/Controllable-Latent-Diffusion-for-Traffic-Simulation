{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f711afb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "%matplotlib inline  \n",
    "\n",
    "import argparse\n",
    "import seaborn as sns\n",
    "import  sys\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from tbsim.utils.log_utils import PrintLogger\n",
    "from tbsim.utils.batch_utils import set_global_batch_type\n",
    "from tbsim.utils.trajdata_utils import set_global_trajdata_batch_env, set_global_trajdata_batch_raster_cfg\n",
    "import tbsim.utils.train_utils as TrainUtils\n",
    "from tbsim.datasets.factory import datamodule_factory\n",
    "from tbsim.utils.env_utils import RolloutCallback\n",
    "\n",
    "import wandb,json\n",
    "from pytorch_lightning.loggers import  WandbLogger\n",
    "from  models.algos import  UnifiedTrainer\n",
    "from datetime import  datetime\n",
    "from configs.custom_config import dict_to_config,ConfigBase,serialize_object\n",
    "from src.tbsim.configs.base import ExperimentConfig\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from trajdata import AgentBatch, AgentType, UnifiedDataset\n",
    "from trajdata.augmentation import NoiseHistories\n",
    "from trajdata.visualization.vis import plot_agent_batch\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Training Script\")\n",
    "parser.add_argument(\"--config\", type=str, default=\"/home/visier/hazardforge/HazardForge/config.yaml\", help=\"Path to YAML config\")\n",
    "\n",
    "# 直接使用默认值解析参数\n",
    "args = parser.parse_args([])  # 在 Notebook 中使用 [] 表示不传递命令行参数\n",
    "\n",
    "# 加载配置文件\n",
    "with open(args.config, \"r\") as f:\n",
    "    config_dict = yaml.safe_load(f)\n",
    "train_config = dict_to_config(ConfigBase, config_dict.get(\"train\", {}))\n",
    "env_config = dict_to_config(ConfigBase, config_dict.get(\"env\", {}))\n",
    "algo_config = dict_to_config(ConfigBase, config_dict.get(\"algo\", {}))\n",
    "default_config = ExperimentConfig(\n",
    "        train_config=train_config,\n",
    "        env_config=env_config,\n",
    "        algo_config=algo_config,\n",
    "        registered_name=config_dict.get(\"registered_name\", \"default_experiment\"),\n",
    "    )\n",
    "if default_config.train.rollout.get(\"enabled\", False):\n",
    "        default_config.env[\"eval\"] = {\"env\": default_config.env[\"name\"]}\n",
    "        assert default_config.algo[\"eval_class\"], f\"Please set an eval_class for {default_config.algo['name']}\"\n",
    "        default_config.env[\"eval\"][\"eval_class\"] = default_config.algo[\"eval_class\"]\n",
    "        default_config.env[\"eval\"][\"dataset_path\"] = default_config.train[\"trajdata_data_dirs\"][\"nusc_trainval\"]\n",
    "        env_specific_config = default_config.env.get(default_config.env[\"eval\"][\"env\"], {})\n",
    "        for key, value in env_specific_config.items():\n",
    "            default_config.env[\"eval\"][key] = value\n",
    "default_config.lock()\n",
    "cfg = default_config\n",
    "pl.seed_everything(cfg.seed)\n",
    "set_global_batch_type(\"trajdata\")\n",
    "set_global_trajdata_batch_env(cfg.train.trajdata_source_train[0])\n",
    "set_global_trajdata_batch_raster_cfg(cfg.env.rasterizer)\n",
    "print(\"\\n============= New Training Run with Config =============\")\n",
    "datamodule = datamodule_factory(\n",
    "        cls_name=cfg.train.datamodule_class, config=cfg\n",
    "    )\n",
    "\n",
    "datamodule.setup()\n",
    "model = UnifiedTrainer(algo_config=cfg.algo,train_config=cfg.train,\n",
    "                           modality_shapes=datamodule.modality_shapes,\n",
    "                           registered_name=cfg.registered_name,\n",
    "                           train_mode=cfg.train.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acf536d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tbsim.utils.batch_utils import batch_utils\n",
    "train_loader = datamodule.train_dataloader()\n",
    "batch = next(iter(train_loader))\n",
    "batch = batch_utils().parse_batch(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562ab8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=10\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "image = batch['image'][idx]  # (34, 224, 224)\n",
    "sem_channel1 = image[-1].detach().cpu().numpy()\n",
    "sem_channel2 = image[-2].detach().cpu().numpy()\n",
    "sem_channel3 = image[-3].detach().cpu().numpy()\n",
    "\n",
    "def normalize(x):\n",
    "    x = x - x.min()\n",
    "    if x.max() > 0:\n",
    "        x = x / x.max()\n",
    "    return x\n",
    "\n",
    "r = normalize(sem_channel1)\n",
    "g = normalize(sem_channel2)\n",
    "b = normalize(sem_channel3)\n",
    "\n",
    "rgb = np.stack([r,g,b], axis=-1) \n",
    "rgb = rgb*0.4+0.6\n",
    "\n",
    "history_length = image.shape[0] - 3  \n",
    "hist_image = image[:history_length].detach().cpu().numpy()  # shape: (history_length, H, W)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "alpha = 0.5\n",
    "\n",
    "def frame_to_image(frame_data):\n",
    "    overlay = np.zeros_like(rgb)\n",
    "    overlay[frame_data == 1] = [0, 1, 0]\n",
    "    overlay[frame_data == -1] = [1, 0, 0]\n",
    "    combined = rgb * (1 - alpha) + overlay * alpha\n",
    "    return combined\n",
    "\n",
    "\n",
    "initial_combined = frame_to_image(hist_image[0])\n",
    "im = ax.imshow(initial_combined, animated=True)\n",
    "ax.axis('off')\n",
    "\n",
    "def update(frame):\n",
    "    current_combined = frame_to_image(hist_image[frame])\n",
    "    im.set_array(current_combined)\n",
    "    return [im]\n",
    "\n",
    "ani = animation.FuncAnimation(fig, update, frames=range(history_length), interval=200, blit=True)\n",
    "\n",
    "HTML(ani.to_jshtml())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6c8cec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73089a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "drivable_map = batch['drivable_map'][idx].detach().cpu().numpy()\n",
    "maps = batch['maps'][idx].detach().cpu().numpy().transpose(1, 2, 0)*0.5+0.5\n",
    "# maps = maps * drivable_map[..., None]\n",
    "fig, axes = plt.subplots(1, 3, figsize=(10, 5))\n",
    "axes[0].imshow(drivable_map, cmap='gray')\n",
    "axes[1].imshow(maps)\n",
    "axes[2].imshow(maps * drivable_map[..., None])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2beb691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(batch,idx):\n",
    "    maps = batch['maps'][idx].detach().cpu().numpy()\n",
    "    maps_rgb = maps.transpose(1, 2, 0)\n",
    "    maps_rgb=maps_rgb*0.4+0.7\n",
    "\n",
    "    traj_state = batch['target_positions'].detach().cpu().numpy()\n",
    "    raster_from_agent = batch['raster_from_agent'].detach().cpu().numpy()\n",
    "    B, T, _ = traj_state.shape\n",
    "    ones = np.ones((B, T, 1))\n",
    "    traj_homo = np.concatenate([traj_state, ones], axis=-1)\n",
    "    traj_homo_T = np.transpose(traj_homo, (0, 2, 1))\n",
    "    traj_raster = np.matmul(raster_from_agent, traj_homo_T)\n",
    "    traj_raster = np.transpose(traj_raster, (0, 2, 1))\n",
    "    traj_raster_xy = traj_raster[..., :2]\n",
    "    traj_xy = traj_raster_xy[idx]\n",
    "\n",
    "    \n",
    "    plt.imshow(maps_rgb)\n",
    "    plt.plot(traj_xy[:, 0], traj_xy[:, 1], color='purple', linewidth=1.5, label='Trajectory')\n",
    "    plt.plot(traj_xy[0, 0], traj_xy[0, 1], marker='s', color='green', markersize=2, label='Start')\n",
    "    plt.plot(traj_xy[-1, 0], traj_xy[-1, 1], marker='s', color='red', markersize=2, label='End')\n",
    "\n",
    "\n",
    "  # maps_rgb是一个HWC格式的图像数组\n",
    "    plt.axis('off')    # 不显示坐标轴（可选）\n",
    "    plt.show()\n",
    "visualize(batch,idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c203694",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_info,_,scaled_input = model.pre_vae(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547ae48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.models.dm_mlp import MLPTimeEmbedding\n",
    "t = torch.randint(0,1000,(8,),)\n",
    "model = MLPTimeEmbedding()\n",
    "time = model(t)\n",
    "time.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9824b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
